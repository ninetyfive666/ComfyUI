** ComfyUI startup time: 2024-04-17 12:22:17.513706
[2024-04-17 12:22] ** Platform: Windows
[2024-04-17 12:22] ** Python version: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
[2024-04-17 12:22] ** Python executable: C:\Users\konst\AppData\Local\Programs\Python\Python310\python.exe
[2024-04-17 12:22] ** Log path: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\comfyui.log
[2024-04-17 12:22] 
#######################################################################
[2024-04-17 12:22] [ComfyUI-Manager] Starting dependency installation/(de)activation for the extension
[2024-04-17 12:22] 
[2024-04-17 12:22] Install: pip packages for 'C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR'
[2024-04-17 12:22] 
[ComfyUI-Manager] Startup script completed.
[2024-04-17 12:22] #######################################################################
[2024-04-17 12:22] 
[2024-04-17 12:22] 
Prestartup times for custom nodes:
[2024-04-17 12:22]    0.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\rgthree-comfy
[2024-04-17 12:22]    1.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-04-17 12:22] 
[2024-04-17 12:22] Total VRAM 24564 MB, total RAM 65416 MB
[2024-04-17 12:22] Set vram state to: NORMAL_VRAM
[2024-04-17 12:22] Device: cuda:0 NVIDIA GeForce RTX 4090 : cudaMallocAsync
[2024-04-17 12:22] VAE dtype: torch.bfloat16
C:\Users\konst\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\utils\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
[2024-04-17 12:22] Using pytorch cross attention
[2024-04-17 12:22] ### Loading: ComfyUI-Manager (V1.25.3)
[2024-04-17 12:22] ### ComfyUI Revision: 2036 [309d5d27] | Released on '2024-03-05'
[2024-04-17 12:22] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-04-17 12:22] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-17 12:22] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2024-04-17 12:22] FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[2024-04-17 12:22] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[2024-04-17 12:22] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2024-04-17 12:22] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-04-17 12:22] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-04-17 12:22] no module 'xformers'. Processing without...
[2024-04-17 12:22] no module 'xformers'. Processing without...
[2024-04-17 12:22] [36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\comfyui_controlnet_aux\ckpts[0m
[2024-04-17 12:22] [36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False[0m
[2024-04-17 12:22] [36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider'][0m
[2024-04-17 12:22] [36mEfficiency Nodes:[0m Attempting to add Control Net options to the 'HiRes-Fix Script' Node (comfyui_controlnet_aux add-on)...[92mSuccess![0m
[2024-04-17 12:22] 
[2024-04-17 12:22] [32m[1m[rgthree] Loaded 22 exciting nodes.[0m
[2024-04-17 12:22] [32m[rgthree] Optimizing ComfyUI recursive execution. [33mIf queueing and/or re-queueing seems broken, change "patch_recursive_execution" to false in rgthree_config.json [0m
[2024-04-17 12:22] 
[2024-04-17 12:22] 
Import times for custom nodes:
[2024-04-17 12:22]    0.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI_IPAdapter_plus
[2024-04-17 12:22]    0.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI-seamless-tiling
[2024-04-17 12:22]    0.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI_UltimateSDUpscale
[2024-04-17 12:22]    0.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\efficiency-nodes-comfyui
[2024-04-17 12:22]    0.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\rgthree-comfy
[2024-04-17 12:22]    0.1 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI-Flowty-LDSR
[2024-04-17 12:22]    0.4 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-04-17 12:22]    0.9 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\comfyui_controlnet_aux
[2024-04-17 12:22]    2.0 seconds: C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR
[2024-04-17 12:22] 
[2024-04-17 12:22] Starting server
[2024-04-17 12:22] 
[2024-04-17 12:22] To see the GUI go to: http://127.0.0.1:8188
[2024-04-17 12:28] got prompt
[2024-04-17 12:28] model_type EPS
[2024-04-17 12:28] adm 2816
[2024-04-17 12:28] Using pytorch attention in VAE
[2024-04-17 12:28] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-04-17 12:28] Using pytorch attention in VAE
[2024-04-17 12:28] clip missing: ['clip_l.logit_scale', 'clip_l.transformer.text_projection.weight']
[2024-04-17 12:28] clip unexpected: ['clip_l.transformer.text_model.embeddings.position_ids']
[2024-04-17 12:29] Requested to load SDXLClipModel
[2024-04-17 12:29] Loading 1 new model
[2024-04-17 12:29] Requested to load SDXL
[2024-04-17 12:29] Loading 1 new model
[2024-04-17 12:29] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:11<00:00,  5.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:11<00:00,  5.37it/s]
[2024-04-17 12:29] Requested to load AutoencoderKL
[2024-04-17 12:29] Loading 1 new model
[2024-04-17 12:29] model_type EPS
[2024-04-17 12:29] adm 2816
[2024-04-17 12:29] Using pytorch attention in VAE
[2024-04-17 12:29] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-04-17 12:29] Using pytorch attention in VAE
[2024-04-17 12:29] clip missing: ['clip_l.logit_scale', 'clip_l.transformer.text_projection.weight']
[2024-04-17 12:29] clip unexpected: ['clip_l.transformer.text_model.embeddings.position_ids']
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_proj_in.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_proj_out.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.alpha
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight
[2024-04-17 12:29] lora key not loaded lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight
[2024-04-17 12:29] Requested to load SDXLClipModel
[2024-04-17 12:29] Loading 1 new model
[2024-04-17 12:29] Requested to load SDXL
[2024-04-17 12:29] Loading 1 new model
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.proj_in.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.proj_out.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight shape '[640, 2560]' is invalid for input of size 6553600
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight shape '[5120, 640]' is invalid for input of size 13107200
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.proj_in.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.proj_out.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight shape '[640, 2560]' is invalid for input of size 6553600
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight shape '[5120, 640]' is invalid for input of size 13107200
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.proj_in.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.proj_out.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight shape '[640, 2560]' is invalid for input of size 6553600
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:29] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight shape '[5120, 640]' is invalid for input of size 13107200
[2024-04-17 12:29] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:09<00:00,  3.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:09<00:00,  3.33it/s]
[2024-04-17 12:29] Requested to load AutoencoderKL
[2024-04-17 12:29] Loading 1 new model
[2024-04-17 12:29] Diffusion using fp16
[2024-04-17 12:29] making attention of type 'vanilla' with 512 in_channels
[2024-04-17 12:29] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-04-17 12:29] making attention of type 'vanilla' with 512 in_channels
[2024-04-17 12:29] Attempting to load SDXL model: [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\juggernautXL_v8Rundiffusion.safetensors]
[2024-04-17 12:29] Loaded state_dict from [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\juggernautXL_v8Rundiffusion.safetensors]
[2024-04-17 12:29] Loading first clip model from SDXL checkpoint
[2024-04-17 12:29] Loading second clip model from SDXL checkpoint
[2024-04-17 12:29] Attempting to load SUPIR model: [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\SUPIR-v0F_fp16.safetensors]
[2024-04-17 12:29] Loaded state_dict from [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\SUPIR-v0F_fp16.safetensors]
[2024-04-17 12:29] captions:  [['']]
[2024-04-17 12:29] Batch captioning
[2024-04-17 12:29] ERROR:root:!!! Exception during processing !!!
[2024-04-17 12:29] ERROR:root:Traceback (most recent call last):
  File "C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\execution.py", line 152, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\execution.py", line 82, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\execution.py", line 75, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR\nodes_v2.py", line 626, in condition
    return ({"cond": c, "original_size":latents["original_size"]}, {"uncond": uc},)
KeyError: 'original_size'

[2024-04-17 12:29] Prompt executed in 79.15 seconds
[2024-04-17 12:30] got prompt
[2024-04-17 12:30] Requested to load SDXLClipModel
[2024-04-17 12:30] Loading 1 new model
[2024-04-17 12:30] Requested to load SDXL
[2024-04-17 12:30] Loading 1 new model
[2024-04-17 12:30] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:11<00:00,  5.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:11<00:00,  5.31it/s]
[2024-04-17 12:30] Requested to load AutoencoderKL
[2024-04-17 12:30] Loading 1 new model
[2024-04-17 12:30] Requested to load SDXL
[2024-04-17 12:30] Loading 1 new model
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 491520
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight shape '[1280, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.proj_in.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.proj_out.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight shape '[640, 2560]' is invalid for input of size 6553600
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight shape '[5120, 640]' is invalid for input of size 13107200
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.proj_in.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.proj_out.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight shape '[640, 2560]' is invalid for input of size 6553600
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight shape '[5120, 640]' is invalid for input of size 13107200
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.proj_in.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.proj_out.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight shape '[640, 2560]' is invalid for input of size 6553600
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight shape '[640, 2048]' is invalid for input of size 983040
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight shape '[640, 640]' is invalid for input of size 1638400
[2024-04-17 12:30] ERROR diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight shape '[5120, 640]' is invalid for input of size 13107200
[2024-04-17 12:30] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.54it/s]
[2024-04-17 12:30] Requested to load AutoencoderKL
[2024-04-17 12:30] Loading 1 new model
[2024-04-17 12:30] Diffusion using fp16
[2024-04-17 12:30] Diffusion using bf16
[2024-04-17 12:30] Encoder using bf16
[2024-04-17 12:30] Using tiled sampling
[2024-04-17 12:30] making attention of type 'vanilla' with 512 in_channels
[2024-04-17 12:30] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-04-17 12:30] making attention of type 'vanilla' with 512 in_channels
[2024-04-17 12:30] Attempting to load SUPIR model: [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\SUPIR-v0F_fp16.safetensors]
[2024-04-17 12:30] Loaded state_dict from [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\SUPIR-v0F_fp16.safetensors]
[2024-04-17 12:30] Attempting to load SDXL model: [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\juggernautXL_v8Rundiffusion.safetensors]
[2024-04-17 12:30] Loaded state_dict from [C:\Users\konst\OneDrive\Dokumente\GitHub\ComfyUI\models\checkpoints\juggernautXL_v8Rundiffusion.safetensors]
