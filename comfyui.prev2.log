## ComfyUI-Manager: installing dependencies done.
[2024-06-18 10:37] ** ComfyUI startup time: 2024-06-18 10:37:20.693823
[2024-06-18 10:37] ** Platform: Windows
[2024-06-18 10:37] ** Python version: 3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]
[2024-06-18 10:37] ** Python executable: C:\Python310\python.exe
[2024-06-18 10:37] ** Log path: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfyui.log
[2024-06-18 10:37] 
#######################################################################
[2024-06-18 10:37] [ComfyUI-Manager] Starting dependency installation/(de)activation for the extension
[2024-06-18 10:37] 
[2024-06-18 10:37] Install: pip packages for 'C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\comfyui_controlnet_aux'
[!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [2024-06-18 10:37]   [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]              [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]  [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]  [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]                                  [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] Install: pip packages for 'C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\efficiency-nodes-comfyui'
[2024-06-18 10:37] Install: pip packages for 'C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager'
[!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [2024-06-18 10:37]    [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]               [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]  Collecting typer
[2024-06-18 10:37]    Obtaining dependency information for typer from https://files.pythonhosted.org/packages/20/b5/11cf2e34fbb11b937e006286ab5b8cfd334fde1c8fa4dd7f491226931180/typer-0.12.3-py3-none-any.whl.metadata
[2024-06-18 10:37]    Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)
[2024-06-18 10:37]    Collecting shellingham>=1.3.0 (from typer)
[2024-06-18 10:37]    Obtaining dependency information for shellingham>=1.3.0 from https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl.metadata
[2024-06-18 10:37]    Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)
[2024-06-18 10:37]  Collecting rich>=10.11.0 (from typer)
[2024-06-18 10:37]    Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata
[2024-06-18 10:37]    Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)
[2024-06-18 10:37]      Downloading typer-0.12.3-py3-none-any.whl (47 kB)
[2024-06-18 10:37]     ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00
[2024-06-18 10:37]  Downloading rich-13.7.1-py3-none-any.whl (240 kB)
[2024-06-18 10:37]     ---------------------------------------- 240.7/240.7 kB 4.9 MB/s eta 0:00:00
[2024-06-18 10:37]  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]  Installing collected packages: shellingham, rich, typer
[2024-06-18 10:37] [!]   WARNING: Failed to write executable - trying to use .deleteme logic
[2024-06-18 10:37] [!] ERROR: Could not install packages due to an OSError: [WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Python310\\Scripts\\typer.exe' -> 'C:\\Python310\\Scripts\\typer.exe.deleteme'
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]     [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37]  [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] Install: pip packages for 'C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\rgthree-comfy'
[2024-06-18 10:37] Install: pip packages for 'C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR'
[!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [2024-06-18 10:37]  [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] WARNING: Ignoring invalid distribution -illow (c:\users\lightmapper\appdata\roaming\python\python310\site-packages)
[2024-06-18 10:37] [!] 
[2024-06-18 10:37] [!] [notice] A new release of pip is available: 23.2.1 -> 24.0
[2024-06-18 10:37] [!] [notice] To update, run: python.exe -m pip install --upgrade pip
[2024-06-18 10:37] 
[ComfyUI-Manager] Startup script completed.
[2024-06-18 10:37] #######################################################################
[2024-06-18 10:37] 
[2024-06-18 10:37] 
Prestartup times for custom nodes:
[2024-06-18 10:37]    0.0 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\rgthree-comfy
[2024-06-18 10:37]   21.3 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-06-18 10:37] 
Total VRAM 24576 MB, total RAM 130987 MB
[2024-06-18 10:37] pytorch version: 2.1.2+cu121
[2024-06-18 10:37] Set vram state to: NORMAL_VRAM
[2024-06-18 10:37] Device: cuda:0 NVIDIA GeForce RTX 3090 : cudaMallocAsync
[2024-06-18 10:37] Using pytorch cross attention
[2024-06-18 10:37] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1906, in load_custom_node
    module_spec.loader.exec_module(module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy_extras\nodes_upscale_model.py", line 3, in <module>
    from spandrel import ModelLoader, ImageModelDescriptor
ModuleNotFoundError: No module named 'spandrel'

[2024-06-18 10:37] Cannot import C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy_extras\nodes_upscale_model.py module for custom nodes: No module named 'spandrel'
[2024-06-18 10:37] ### Loading: ComfyUI-Manager (V2.38.1)
[2024-06-18 10:37] ### ComfyUI Revision: 2280 [0e4d9424] | Released on '2024-06-18'
[2024-06-18 10:37] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json
[2024-06-18 10:37] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json
[2024-06-18 10:37] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json
[2024-06-18 10:37] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json
[2024-06-18 10:37] [ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json
[2024-06-18 10:37] no module 'xformers'. Processing without...
[2024-06-18 10:37] no module 'xformers'. Processing without...
[2024-06-18 10:37] [36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\comfyui_controlnet_aux\ckpts[0m
[2024-06-18 10:37] [36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False[0m
[2024-06-18 10:37] [36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider'][0m
[2024-06-18 10:37] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1906, in load_custom_node
    module_spec.loader.exec_module(module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI_UltimateSDUpscale\__init__.py", line 32, in <module>
    from .nodes import NODE_CLASS_MAPPINGS, NODE_DISPLAY_NAME_MAPPINGS
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI_UltimateSDUpscale\nodes.py", line 10, in <module>
    from modules.upscaler import UpscalerData
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI_UltimateSDUpscale\modules\upscaler.py", line 3, in <module>
    from comfy_extras.nodes_upscale_model import ImageUpscaleWithModel
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy_extras\nodes_upscale_model.py", line 3, in <module>
    from spandrel import ModelLoader, ImageModelDescriptor
ModuleNotFoundError: No module named 'spandrel'

[2024-06-18 10:37] Cannot import C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI_UltimateSDUpscale module for custom nodes: No module named 'spandrel'
[2024-06-18 10:37] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1906, in load_custom_node
    module_spec.loader.exec_module(module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\efficiency-nodes-comfyui\__init__.py", line 9, in <module>
    from  .efficiency_nodes import NODE_CLASS_MAPPINGS
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\efficiency-nodes-comfyui\efficiency_nodes.py", line 36, in <module>
    from comfy_extras.nodes_upscale_model import UpscaleModelLoader, ImageUpscaleWithModel
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy_extras\nodes_upscale_model.py", line 3, in <module>
    from spandrel import ModelLoader, ImageModelDescriptor
ModuleNotFoundError: No module named 'spandrel'

[2024-06-18 10:37] Cannot import C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\efficiency-nodes-comfyui module for custom nodes: No module named 'spandrel'
[2024-06-18 10:37] 
[2024-06-18 10:37] [92m[rgthree] Loaded 40 magnificent nodes.[0m
[2024-06-18 10:37] [92m[rgthree] Will use rgthree's optimized recursive execution.[0m
[2024-06-18 10:37] 
[2024-06-18 10:37] 
Import times for custom nodes:
[2024-06-18 10:37]    0.0 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\websocket_image_save.py
[2024-06-18 10:37]    0.0 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-seamless-tiling
[2024-06-18 10:37]    0.0 seconds (IMPORT FAILED): C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI_UltimateSDUpscale
[2024-06-18 10:37]    0.0 seconds (IMPORT FAILED): C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\efficiency-nodes-comfyui
[2024-06-18 10:37]    0.0 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI_IPAdapter_plus
[2024-06-18 10:37]    0.0 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\rgthree-comfy
[2024-06-18 10:37]    0.0 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Flowty-LDSR
[2024-06-18 10:37]    0.3 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager
[2024-06-18 10:37]    0.4 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Flowty-TripoSR
[2024-06-18 10:37]    0.4 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\comfyui_controlnet_aux
[2024-06-18 10:37]    0.9 seconds: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR
[2024-06-18 10:37] 
[2024-06-18 10:37] WARNING: some comfy_extras/ nodes did not import correctly. This may be because they are missing some dependencies.

[2024-06-18 10:37] IMPORT FAILED: nodes_upscale_model.py
[2024-06-18 10:37] 
This issue might be caused by new missing dependencies added the last time you updated ComfyUI.
[2024-06-18 10:37] Please do a: pip install -r requirements.txt
[2024-06-18 10:37] 
[2024-06-18 10:37] Starting server

[2024-06-18 10:37] To see the GUI go to: http://127.0.0.1:8188
[2024-06-18 10:39] got prompt
[2024-06-18 10:39] Failed to validate prompt for output 233:
[2024-06-18 10:39] * TripleCLIPLoader 11:
[2024-06-18 10:39]   - Required input is missing: clip_name1
[2024-06-18 10:39]   - Required input is missing: clip_name2
[2024-06-18 10:39]   - Required input is missing: clip_name3
[2024-06-18 10:39] Output will be ignored
[2024-06-18 10:39] invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}
[2024-06-18 10:41] got prompt
[2024-06-18 10:41] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 10:41] [32m[rgthree][0m First run patching recursive_output_delete_if_changed and recursive_will_execute.[0m
[2024-06-18 10:41] [33m[rgthree] Note: [0mIf execution seems broken due to forward ComfyUI changes, you can disable the optimization from rgthree settings in ComfyUI.[0m
[2024-06-18 10:41] model_type FLOW
[2024-06-18 10:41] Using pytorch attention in VAE
[2024-06-18 10:41] Using pytorch attention in VAE
[2024-06-18 10:41] Processing interrupted
[2024-06-18 10:41] Prompt executed in 13.76 seconds
[2024-06-18 11:15] got prompt
[2024-06-18 11:15] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:15] Requested to load SD3ClipModel_
[2024-06-18 11:15] Loading 1 new model
[2024-06-18 11:15] Requested to load SD3
[2024-06-18 11:15] Loading 1 new model
[2024-06-18 11:15] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:11<00:00,  2.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:11<00:00,  2.53it/s]
[2024-06-18 11:15] Requested to load AutoencodingEngine
[2024-06-18 11:15] Loading 1 new model
[2024-06-18 11:15] Prompt executed in 15.82 seconds
[2024-06-18 11:26] got prompt
[2024-06-18 11:26] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:26] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:10<00:00,  2.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:10<00:00,  2.78it/s]
[2024-06-18 11:26] Prompt executed in 10.94 seconds
[2024-06-18 11:26] got prompt
[2024-06-18 11:26] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:26] Prompt executed in 0.00 seconds
[2024-06-18 11:26] got prompt
[2024-06-18 11:26] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:27] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:21<00:00,  2.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:21<00:00,  2.74it/s]
[2024-06-18 11:27] Prompt executed in 22.29 seconds
[2024-06-18 11:27] got prompt
[2024-06-18 11:27] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:28] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:21<00:00,  2.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:21<00:00,  2.77it/s]
[2024-06-18 11:28] Prompt executed in 22.33 seconds
[2024-06-18 11:28] got prompt
[2024-06-18 11:28] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:28] Requested to load SD3
[2024-06-18 11:28] Loading 1 new model
[2024-06-18 11:28] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.75it/s]
[2024-06-18 11:28] Prompt executed in 14.94 seconds
[2024-06-18 11:30] got prompt
[2024-06-18 11:30] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:30] Requested to load SD3
[2024-06-18 11:30] Loading 1 new model
[2024-06-18 11:30] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.78it/s]
[2024-06-18 11:30] Prompt executed in 14.78 seconds
[2024-06-18 11:30] got prompt
[2024-06-18 11:30] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:30] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]
[2024-06-18 11:30] Prompt executed in 14.97 seconds
[2024-06-18 11:31] got prompt
[2024-06-18 11:31] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:31] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]
[2024-06-18 11:31] Prompt executed in 15.01 seconds
[2024-06-18 11:38] got prompt
[2024-06-18 11:38] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:38] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.73it/s]
[2024-06-18 11:38] Prompt executed in 15.04 seconds
[2024-06-18 11:47] got prompt
[2024-06-18 11:47] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:47] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]
[2024-06-18 11:47] Prompt executed in 14.99 seconds
[2024-06-18 11:48] got prompt
[2024-06-18 11:48] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:48] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]
[2024-06-18 11:48] Prompt executed in 15.42 seconds
[2024-06-18 11:48] got prompt
[2024-06-18 11:48] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:48] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.70it/s]
[2024-06-18 11:48] Prompt executed in 15.21 seconds
[2024-06-18 11:48] got prompt
[2024-06-18 11:48] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:49] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]
[2024-06-18 11:49] Prompt executed in 15.52 seconds
[2024-06-18 11:50] got prompt
[2024-06-18 11:50] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:50] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.68it/s]
[2024-06-18 11:50] Prompt executed in 15.77 seconds
[2024-06-18 11:50] got prompt
[2024-06-18 11:50] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:50] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.73it/s]
[2024-06-18 11:50] Prompt executed in 15.04 seconds
[2024-06-18 11:50] got prompt
[2024-06-18 11:50] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:51] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]
[2024-06-18 11:51] Prompt executed in 14.98 seconds
[2024-06-18 11:51] got prompt
[2024-06-18 11:51] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:51] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.67it/s]
[2024-06-18 11:51] Prompt executed in 15.87 seconds
[2024-06-18 11:53] got prompt
[2024-06-18 11:53] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:54] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.67it/s]
[2024-06-18 11:54] model_type EPS
[2024-06-18 11:54] Using pytorch attention in VAE
[2024-06-18 11:54] Using pytorch attention in VAE
[2024-06-18 11:54] Requested to load SDXL
[2024-06-18 11:54] Loading 1 new model
[2024-06-18 11:54] 
[2024-06-18 11:54] !!! Exception during processing!!! mat1 and mat2 shapes cannot be multiplied (2x3584 and 2816x1280)
[2024-06-18 11:54] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1371, in sample
    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1341, in common_ksampler
    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\sample.py", line 43, in sample
    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 794, in sample
    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 696, in sample
    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 683, in sample
    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 662, in inner_sample
    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 567, in sample
    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)
  File "C:\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\k_diffusion\sampling.py", line 142, in sample_euler
    denoised = model(x, sigma_hat * s_in, **extra_args)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 291, in __call__
    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 649, in __call__
    return self.predict_noise(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 652, in predict_noise
    return sampling_function(self.inner_model, x, timestep, self.conds.get("negative", None), self.conds.get("positive", None), self.cfg, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 277, in sampling_function
    out = calc_cond_batch(model, conds, x, timestep, model_options)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 226, in calc_cond_batch
    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\model_base.py", line 113, in apply_model
    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 847, in forward
    emb = emb + self.label_emb(y)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\container.py", line 215, in forward
    input = module(input)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\container.py", line 215, in forward
    input = module(input)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ops.py", line 52, in forward
    return super().forward(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (2x3584 and 2816x1280)

[2024-06-18 11:54] Prompt executed in 43.13 seconds
[2024-06-18 11:54] got prompt
[2024-06-18 11:54] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 11:54] Requested to load SD3
[2024-06-18 11:54] Loading 1 new model
[2024-06-18 11:54] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.69it/s]
[2024-06-18 11:54] Requested to load AutoencodingEngine
[2024-06-18 11:54] Loading 1 new model
[2024-06-18 11:54] 
[2024-06-18 11:54] !!! Exception during processing!!! mat1 and mat2 shapes cannot be multiplied (2x3584 and 2816x1280)
[2024-06-18 11:54] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1371, in sample
    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1341, in common_ksampler
    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\sample.py", line 43, in sample
    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 794, in sample
    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 696, in sample
    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 683, in sample
    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 662, in inner_sample
    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 567, in sample
    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)
  File "C:\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\k_diffusion\sampling.py", line 599, in sample_dpmpp_2m
    denoised = model(x, sigmas[i] * s_in, **extra_args)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 291, in __call__
    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 649, in __call__
    return self.predict_noise(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 652, in predict_noise
    return sampling_function(self.inner_model, x, timestep, self.conds.get("negative", None), self.conds.get("positive", None), self.cfg, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 277, in sampling_function
    out = calc_cond_batch(model, conds, x, timestep, model_options)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 226, in calc_cond_batch
    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\model_base.py", line 113, in apply_model
    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 847, in forward
    emb = emb + self.label_emb(y)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\container.py", line 215, in forward
    input = module(input)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\container.py", line 215, in forward
    input = module(input)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ops.py", line 52, in forward
    return super().forward(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (2x3584 and 2816x1280)

[2024-06-18 11:54] Prompt executed in 17.76 seconds
[2024-06-18 11:58] FETCH DATA from: C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-Manager\extension-node-map.json [DONE]
[2024-06-18 12:02] got prompt
[2024-06-18 12:02] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:02] Requested to load SD3
[2024-06-18 12:02] Loading 1 new model
[2024-06-18 12:02] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.70it/s]
[2024-06-18 12:02] Requested to load SDXLClipModel
[2024-06-18 12:02] Loading 1 new model
[2024-06-18 12:02] 
[2024-06-18 12:02] !!! Exception during processing!!! Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead
[2024-06-18 12:02] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1371, in sample
    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1341, in common_ksampler
    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\sample.py", line 43, in sample
    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 794, in sample
    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 696, in sample
    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 683, in sample
    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 662, in inner_sample
    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 567, in sample
    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)
  File "C:\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\k_diffusion\sampling.py", line 599, in sample_dpmpp_2m
    denoised = model(x, sigmas[i] * s_in, **extra_args)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 291, in __call__
    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 649, in __call__
    return self.predict_noise(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 652, in predict_noise
    return sampling_function(self.inner_model, x, timestep, self.conds.get("negative", None), self.conds.get("positive", None), self.cfg, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 277, in sampling_function
    out = calc_cond_batch(model, conds, x, timestep, model_options)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 226, in calc_cond_batch
    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\model_base.py", line 113, in apply_model
    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 852, in forward
    h = forward_timestep_embed(module, h, emb, context, transformer_options, time_context=time_context, num_video_frames=num_video_frames, image_only_indicator=image_only_indicator)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 50, in forward_timestep_embed
    x = layer(x)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ops.py", line 80, in forward
    return super().forward(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead

[2024-06-18 12:02] Prompt executed in 17.03 seconds
[2024-06-18 12:02] got prompt
[2024-06-18 12:02] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:02] Requested to load SD3
[2024-06-18 12:02] Loading 1 new model
[2024-06-18 12:03] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.70it/s]
[2024-06-18 12:03] Requested to load AutoencodingEngine
[2024-06-18 12:03] Loading 1 new model
[2024-06-18 12:03] 
[2024-06-18 12:03] !!! Exception during processing!!! Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead
[2024-06-18 12:03] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1371, in sample
    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1341, in common_ksampler
    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\sample.py", line 43, in sample
    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 794, in sample
    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 696, in sample
    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 683, in sample
    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 662, in inner_sample
    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 567, in sample
    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)
  File "C:\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\k_diffusion\sampling.py", line 599, in sample_dpmpp_2m
    denoised = model(x, sigmas[i] * s_in, **extra_args)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 291, in __call__
    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 649, in __call__
    return self.predict_noise(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 652, in predict_noise
    return sampling_function(self.inner_model, x, timestep, self.conds.get("negative", None), self.conds.get("positive", None), self.cfg, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 277, in sampling_function
    out = calc_cond_batch(model, conds, x, timestep, model_options)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 226, in calc_cond_batch
    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\model_base.py", line 113, in apply_model
    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 852, in forward
    h = forward_timestep_embed(module, h, emb, context, transformer_options, time_context=time_context, num_video_frames=num_video_frames, image_only_indicator=image_only_indicator)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 50, in forward_timestep_embed
    x = layer(x)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ops.py", line 80, in forward
    return super().forward(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead

[2024-06-18 12:03] Prompt executed in 17.36 seconds
[2024-06-18 12:04] got prompt
[2024-06-18 12:04] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:04] Requested to load SD3
[2024-06-18 12:04] Loading 1 new model
[2024-06-18 12:04] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.74it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.72it/s]
[2024-06-18 12:04] 
[2024-06-18 12:04] !!! Exception during processing!!! Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead
[2024-06-18 12:04] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1405, in sample
    return common_ksampler(model, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise, disable_noise=disable_noise, start_step=start_at_step, last_step=end_at_step, force_full_denoise=force_full_denoise)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1341, in common_ksampler
    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\sample.py", line 43, in sample
    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 794, in sample
    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 696, in sample
    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 683, in sample
    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 662, in inner_sample
    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 567, in sample
    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)
  File "C:\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\k_diffusion\sampling.py", line 142, in sample_euler
    denoised = model(x, sigma_hat * s_in, **extra_args)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 291, in __call__
    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 649, in __call__
    return self.predict_noise(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 652, in predict_noise
    return sampling_function(self.inner_model, x, timestep, self.conds.get("negative", None), self.conds.get("positive", None), self.cfg, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 277, in sampling_function
    out = calc_cond_batch(model, conds, x, timestep, model_options)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 226, in calc_cond_batch
    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\model_base.py", line 113, in apply_model
    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 852, in forward
    h = forward_timestep_embed(module, h, emb, context, transformer_options, time_context=time_context, num_video_frames=num_video_frames, image_only_indicator=image_only_indicator)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 50, in forward_timestep_embed
    x = layer(x)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ops.py", line 80, in forward
    return super().forward(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead

[2024-06-18 12:04] Prompt executed in 16.48 seconds
[2024-06-18 12:05] got prompt
[2024-06-18 12:05] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:05] model_type EPS
[2024-06-18 12:06] Using pytorch attention in VAE
[2024-06-18 12:06] Using pytorch attention in VAE
[2024-06-18 12:06] Requested to load SDXLClipModel
[2024-06-18 12:06] Loading 1 new model
[2024-06-18 12:06] Requested to load SDXL
[2024-06-18 12:06] Loading 1 new model
[2024-06-18 12:06] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.63it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:11<00:00,  3.63it/s]
[2024-06-18 12:06] Requested to load AutoencoderKL
[2024-06-18 12:06] Loading 1 new model
[2024-06-18 12:06] model_type EPS
[2024-06-18 12:06] Using pytorch attention in VAE
[2024-06-18 12:06] Using pytorch attention in VAE
[2024-06-18 12:06] Processing interrupted
[2024-06-18 12:06] Prompt executed in 48.63 seconds
[2024-06-18 12:08] got prompt
[2024-06-18 12:08] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:08] model_type FLOW
[2024-06-18 12:08] Using pytorch attention in VAE
[2024-06-18 12:08] Using pytorch attention in VAE
[2024-06-18 12:08] Requested to load SD3ClipModel_
[2024-06-18 12:08] Loading 1 new model
[2024-06-18 12:08] Requested to load SD3
[2024-06-18 12:08] Loading 1 new model
[2024-06-18 12:08] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.80it/s]
[2024-06-18 12:08] Requested to load AutoencodingEngine
[2024-06-18 12:08] Loading 1 new model
[2024-06-18 12:08] model_type EPS
[2024-06-18 12:08] Using pytorch attention in VAE
[2024-06-18 12:08] Using pytorch attention in VAE
[2024-06-18 12:08] Requested to load SDXLClipModel
[2024-06-18 12:08] Loading 1 new model
[2024-06-18 12:08] Requested to load SDXL
[2024-06-18 12:08] Loading 1 new model
[2024-06-18 12:09] 
[2024-06-18 12:09] !!! Exception during processing!!! Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead
[2024-06-18 12:09] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1371, in sample
    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\nodes.py", line 1341, in common_ksampler
    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\sample.py", line 43, in sample
    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 794, in sample
    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 696, in sample
    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 683, in sample
    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 662, in inner_sample
    samples = sampler.sample(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 567, in sample
    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)
  File "C:\Python310\lib\site-packages\torch\utils\_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\k_diffusion\sampling.py", line 599, in sample_dpmpp_2m
    denoised = model(x, sigmas[i] * s_in, **extra_args)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 291, in __call__
    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 649, in __call__
    return self.predict_noise(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 652, in predict_noise
    return sampling_function(self.inner_model, x, timestep, self.conds.get("negative", None), self.conds.get("positive", None), self.cfg, model_options=model_options, seed=seed)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 277, in sampling_function
    out = calc_cond_batch(model, conds, x, timestep, model_options)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\samplers.py", line 226, in calc_cond_batch
    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\model_base.py", line 113, in apply_model
    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds).float()
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 852, in forward
    h = forward_timestep_embed(module, h, emb, context, transformer_options, time_context=time_context, num_video_frames=num_video_frames, image_only_indicator=image_only_indicator)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ldm\modules\diffusionmodules\openaimodel.py", line 50, in forward_timestep_embed
    x = layer(x)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\comfy\ops.py", line 80, in forward
    return super().forward(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Python310\lib\site-packages\torch\nn\modules\conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [320, 4, 3, 3], expected input[2, 16, 128, 128] to have 4 channels, but got 16 channels instead

[2024-06-18 12:09] Prompt executed in 46.97 seconds
[2024-06-18 12:13] got prompt
[2024-06-18 12:13] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:13] Requested to load AutoencoderKL
[2024-06-18 12:13] Loading 1 new model
[2024-06-18 12:13] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.55it/s]
[2024-06-18 12:13] Prompt executed in 9.59 seconds
[2024-06-18 12:13] got prompt
[2024-06-18 12:13] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:13] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.38it/s]
[2024-06-18 12:13] Prompt executed in 9.37 seconds
[2024-06-18 12:14] got prompt
[2024-06-18 12:14] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:14] model_type EPS
[2024-06-18 12:14] Using pytorch attention in VAE
[2024-06-18 12:14] Using pytorch attention in VAE
[2024-06-18 12:14] Requested to load SDXLClipModel
[2024-06-18 12:14] Loading 1 new model
[2024-06-18 12:14] Requested to load AutoencoderKL
[2024-06-18 12:14] Loading 1 new model
[2024-06-18 12:14] Requested to load SDXL
[2024-06-18 12:14] Loading 1 new model
[2024-06-18 12:14] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.56it/s]
[2024-06-18 12:14] Prompt executed in 24.14 seconds
[2024-06-18 12:15] got prompt
[2024-06-18 12:15] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:15] Requested to load SD3
[2024-06-18 12:15] Loading 1 new model
[2024-06-18 12:15] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.70it/s]
[2024-06-18 12:15] Requested to load AutoencodingEngine
[2024-06-18 12:15] Loading 1 new model
[2024-06-18 12:15] model_type EPS
[2024-06-18 12:15] Using pytorch attention in VAE
[2024-06-18 12:15] Using pytorch attention in VAE
[2024-06-18 12:15] Requested to load SDXLClipModel
[2024-06-18 12:15] Loading 1 new model
[2024-06-18 12:15] Requested to load AutoencoderKL
[2024-06-18 12:15] Loading 1 new model
[2024-06-18 12:15] Requested to load SDXL
[2024-06-18 12:15] Loading 1 new model
[2024-06-18 12:15] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.52it/s]
[2024-06-18 12:15] Requested to load AutoencoderKL
[2024-06-18 12:15] Loading 1 new model
[2024-06-18 12:15] Prompt executed in 43.42 seconds
[2024-06-18 12:17] got prompt
[2024-06-18 12:17] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:17] Requested to load SD3
[2024-06-18 12:17] Loading 1 new model
[2024-06-18 12:17] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.72it/s]
[2024-06-18 12:17] Requested to load AutoencodingEngine
[2024-06-18 12:17] Loading 1 new model
[2024-06-18 12:17] Prompt executed in 18.12 seconds
[2024-06-18 12:17] got prompt
[2024-06-18 12:17] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:18] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.72it/s]
[2024-06-18 12:18] Prompt executed in 15.14 seconds
[2024-06-18 12:18] got prompt
[2024-06-18 12:18] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:18] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.65it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.72it/s]
[2024-06-18 12:18] Prompt executed in 15.40 seconds
[2024-06-18 12:18] got prompt
[2024-06-18 12:18] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:19] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.75it/s]
[2024-06-18 12:19] Prompt executed in 15.41 seconds
[2024-06-18 12:20] got prompt
[2024-06-18 12:20] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:20] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.71it/s]
[2024-06-18 12:21] Prompt executed in 15.16 seconds
[2024-06-18 12:21] got prompt
[2024-06-18 12:21] Failed to validate prompt for output 312:
[2024-06-18 12:21] * SUPIR_model_loader_v2 308:
[2024-06-18 12:21]   - Required input is missing: model
[2024-06-18 12:21]   - Required input is missing: clip
[2024-06-18 12:21] * VAEDecode 311:
[2024-06-18 12:21]   - Required input is missing: vae
[2024-06-18 12:21] Output will be ignored
[2024-06-18 12:21] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:21] 
[2024-06-18 12:21] Processing interrupted
[2024-06-18 12:21] Prompt executed in 13.55 seconds
[2024-06-18 12:21] got prompt
[2024-06-18 12:21] Failed to validate prompt for output 312:
[2024-06-18 12:21] * VAEDecode 311:
[2024-06-18 12:21]   - Required input is missing: vae
[2024-06-18 12:21] Output will be ignored
[2024-06-18 12:21] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:21] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.76it/s]
[2024-06-18 12:21] Prompt executed in 14.87 seconds
[2024-06-18 12:22] got prompt
[2024-06-18 12:22] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 12:22] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.68it/s]
[2024-06-18 12:22] Loading weights to:  cpu
[2024-06-18 12:22] Diffusion using fp16
[2024-06-18 12:22] making attention of type 'vanilla' with 512 in_channels
[2024-06-18 12:22] Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
[2024-06-18 12:22] making attention of type 'vanilla' with 512 in_channels
[2024-06-18 12:22] Attempting to load SDXL model from node inputs
[2024-06-18 12:22] Requested to load SD3
[2024-06-18 12:22] Loading 1 new model
[2024-06-18 12:22] !!! Exception during processing!!! Failed to load SDXL model
[2024-06-18 12:22] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR\nodes_v2.py", line 883, in process
    set_module_tensor_to_device(self.model, key, device=device, dtype=dtype, value=sdxl_state_dict[key])
  File "C:\Python310\lib\site-packages\accelerate\utils\modeling.py", line 276, in set_module_tensor_to_device
    raise ValueError(f"{module} does not have a parameter or a buffer named {tensor_name}.")
ValueError: LightGLVUNet(
  (time_embed): Sequential(
    (0): Linear(in_features=320, out_features=1280, bias=True)
    (1): SiLU()
    (2): Linear(in_features=1280, out_features=1280, bias=True)
  )
  (label_emb): Sequential(
    (0): Sequential(
      (0): Linear(in_features=2816, out_features=1280, bias=True)
      (1): SiLU()
      (2): Linear(in_features=1280, out_features=1280, bias=True)
    )
  )
  (input_blocks): ModuleList(
    (0): TimestepEmbedSequential(
      (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (1-2): 2 x TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=320, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Identity()
      )
    )
    (3): TimestepEmbedSequential(
      (0): Downsample(
        (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (4): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=640, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=640, out_features=640, bias=True)
        (transformer_blocks): ModuleList(
          (0-1): 2 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=640, out_features=640, bias=False)
              (to_v): Linear(in_features=640, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=640, out_features=5120, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=2560, out_features=640, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=2048, out_features=640, bias=False)
              (to_v): Linear(in_features=2048, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=640, out_features=640, bias=True)
      )
    )
    (5): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=640, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Identity()
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=640, out_features=640, bias=True)
        (transformer_blocks): ModuleList(
          (0-1): 2 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=640, out_features=640, bias=False)
              (to_v): Linear(in_features=640, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=640, out_features=5120, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=2560, out_features=640, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=2048, out_features=640, bias=False)
              (to_v): Linear(in_features=2048, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=640, out_features=640, bias=True)
      )
    )
    (6): TimestepEmbedSequential(
      (0): Downsample(
        (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
    (7): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)
        (transformer_blocks): ModuleList(
          (0-9): 10 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=1280, out_features=1280, bias=False)
              (to_v): Linear(in_features=1280, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=1280, out_features=10240, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=5120, out_features=1280, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=2048, out_features=1280, bias=False)
              (to_v): Linear(in_features=2048, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)
      )
    )
    (8): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Identity()
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)
        (transformer_blocks): ModuleList(
          (0-9): 10 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=1280, out_features=1280, bias=False)
              (to_v): Linear(in_features=1280, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=1280, out_features=10240, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=5120, out_features=1280, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=2048, out_features=1280, bias=False)
              (to_v): Linear(in_features=2048, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)
      )
    )
  )
  (middle_block): TimestepEmbedSequential(
    (0): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1280, out_features=1280, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0, inplace=False)
        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Identity()
    )
    (1): SpatialTransformer(
      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
      (proj_in): Linear(in_features=1280, out_features=1280, bias=True)
      (transformer_blocks): ModuleList(
        (0-9): 10 x BasicTransformerBlock(
          (attn1): CrossAttention(
            (to_q): Linear(in_features=1280, out_features=1280, bias=False)
            (to_k): Linear(in_features=1280, out_features=1280, bias=False)
            (to_v): Linear(in_features=1280, out_features=1280, bias=False)
            (to_out): Sequential(
              (0): Linear(in_features=1280, out_features=1280, bias=True)
              (1): Dropout(p=0.0, inplace=False)
            )
          )
          (ff): FeedForward(
            (net): Sequential(
              (0): GEGLU(
                (proj): Linear(in_features=1280, out_features=10240, bias=True)
              )
              (1): Dropout(p=0.0, inplace=False)
              (2): Linear(in_features=5120, out_features=1280, bias=True)
            )
          )
          (attn2): CrossAttention(
            (to_q): Linear(in_features=1280, out_features=1280, bias=False)
            (to_k): Linear(in_features=2048, out_features=1280, bias=False)
            (to_v): Linear(in_features=2048, out_features=1280, bias=False)
            (to_out): Sequential(
              (0): Linear(in_features=1280, out_features=1280, bias=True)
              (1): Dropout(p=0.0, inplace=False)
            )
          )
          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
      (proj_out): Linear(in_features=1280, out_features=1280, bias=True)
    )
    (2): ResBlock(
      (in_layers): Sequential(
        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (h_upd): Identity()
      (x_upd): Identity()
      (emb_layers): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1280, out_features=1280, bias=True)
      )
      (out_layers): Sequential(
        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
        (1): SiLU()
        (2): Dropout(p=0, inplace=False)
        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (skip_connection): Identity()
    )
  )
  (output_blocks): ModuleList(
    (0-1): 2 x TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)
        (transformer_blocks): ModuleList(
          (0-9): 10 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=1280, out_features=1280, bias=False)
              (to_v): Linear(in_features=1280, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=1280, out_features=10240, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=5120, out_features=1280, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=2048, out_features=1280, bias=False)
              (to_v): Linear(in_features=2048, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)
      )
    )
    (2): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=1280, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)
        (transformer_blocks): ModuleList(
          (0-9): 10 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=1280, out_features=1280, bias=False)
              (to_v): Linear(in_features=1280, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=1280, out_features=10240, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=5120, out_features=1280, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=1280, out_features=1280, bias=False)
              (to_k): Linear(in_features=2048, out_features=1280, bias=False)
              (to_v): Linear(in_features=2048, out_features=1280, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=1280, out_features=1280, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)
      )
      (2): Upsample(
        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (3): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=640, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=640, out_features=640, bias=True)
        (transformer_blocks): ModuleList(
          (0-1): 2 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=640, out_features=640, bias=False)
              (to_v): Linear(in_features=640, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=640, out_features=5120, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=2560, out_features=640, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=2048, out_features=640, bias=False)
              (to_v): Linear(in_features=2048, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=640, out_features=640, bias=True)
      )
    )
    (4): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=640, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=640, out_features=640, bias=True)
        (transformer_blocks): ModuleList(
          (0-1): 2 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=640, out_features=640, bias=False)
              (to_v): Linear(in_features=640, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=640, out_features=5120, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=2560, out_features=640, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=2048, out_features=640, bias=False)
              (to_v): Linear(in_features=2048, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=640, out_features=640, bias=True)
      )
    )
    (5): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=640, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): SpatialTransformer(
        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
        (proj_in): Linear(in_features=640, out_features=640, bias=True)
        (transformer_blocks): ModuleList(
          (0-1): 2 x BasicTransformerBlock(
            (attn1): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=640, out_features=640, bias=False)
              (to_v): Linear(in_features=640, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (ff): FeedForward(
              (net): Sequential(
                (0): GEGLU(
                  (proj): Linear(in_features=640, out_features=5120, bias=True)
                )
                (1): Dropout(p=0.0, inplace=False)
                (2): Linear(in_features=2560, out_features=640, bias=True)
              )
            )
            (attn2): CrossAttention(
              (to_q): Linear(in_features=640, out_features=640, bias=False)
              (to_k): Linear(in_features=2048, out_features=640, bias=False)
              (to_v): Linear(in_features=2048, out_features=640, bias=False)
              (to_out): Sequential(
                (0): Linear(in_features=640, out_features=640, bias=True)
                (1): Dropout(p=0.0, inplace=False)
              )
            )
            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
          )
        )
        (proj_out): Linear(in_features=640, out_features=640, bias=True)
      )
      (2): Upsample(
        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (6): TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=320, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (7-8): 2 x TimestepEmbedSequential(
      (0): ResBlock(
        (in_layers): Sequential(
          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (h_upd): Identity()
        (x_upd): Identity()
        (emb_layers): Sequential(
          (0): SiLU()
          (1): Linear(in_features=1280, out_features=320, bias=True)
        )
        (out_layers): Sequential(
          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
          (1): SiLU()
          (2): Dropout(p=0, inplace=False)
          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (out): Sequential(
    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)
    (1): SiLU()
    (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (project_modules): ModuleList(
    (0-1): 2 x ZeroSFT(
      (param_free_norm): GroupNorm32(32, 640, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): ZeroSFT(
      (param_free_norm): GroupNorm32(32, 960, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
    )
    (3): ZeroCrossAttn(
      (attn): CrossAttention(
        (to_q): Linear(in_features=640, out_features=640, bias=False)
        (to_k): Linear(in_features=320, out_features=640, bias=False)
        (to_v): Linear(in_features=320, out_features=640, bias=False)
        (to_out): Sequential(
          (0): Linear(in_features=640, out_features=640, bias=True)
          (1): Dropout(p=0.0, inplace=False)
        )
      )
      (norm1): GroupNorm32(32, 640, eps=1e-05, affine=True)
      (norm2): GroupNorm32(32, 320, eps=1e-05, affine=True)
    )
    (4): ZeroSFT(
      (param_free_norm): GroupNorm32(32, 960, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
    )
    (5): ZeroSFT(
      (param_free_norm): GroupNorm32(32, 1280, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
    )
    (6): ZeroSFT(
      (param_free_norm): GroupNorm32(32, 1920, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
    )
    (7): ZeroCrossAttn(
      (attn): CrossAttention(
        (to_q): Linear(in_features=1280, out_features=1280, bias=False)
        (to_k): Linear(in_features=640, out_features=1280, bias=False)
        (to_v): Linear(in_features=640, out_features=1280, bias=False)
        (to_out): Sequential(
          (0): Linear(in_features=1280, out_features=1280, bias=True)
          (1): Dropout(p=0.0, inplace=False)
        )
      )
      (norm1): GroupNorm32(32, 1280, eps=1e-05, affine=True)
      (norm2): GroupNorm32(32, 640, eps=1e-05, affine=True)
    )
    (8): ZeroSFT(
      (param_free_norm): GroupNorm32(32, 1920, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
    )
    (9-10): 2 x ZeroSFT(
      (param_free_norm): GroupNorm32(32, 2560, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(1280, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
    )
    (11): ZeroSFT(
      (param_free_norm): GroupNorm32(32, 1280, eps=1e-05, affine=True)
      (mlp_shared): Sequential(
        (0): Conv2d(1280, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): SiLU()
      )
      (zero_mul): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_add): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (zero_conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
    )
  )
) does not have a parameter or a buffer named pos_embed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR\nodes_v2.py", line 893, in process
    raise Exception("Failed to load SDXL model")
Exception: Failed to load SDXL model

[2024-06-18 12:22] Prompt executed in 43.61 seconds
[2024-06-18 13:50] got prompt
[2024-06-18 13:50] [32m[rgthree] Using rgthree's optimized recursive execution.[0m
[2024-06-18 13:50] Requested to load SD3
[2024-06-18 13:50] Loading 1 new model
[2024-06-18 13:50] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:14<00:00,  2.75it/s]
[2024-06-18 13:50] Requested to load AutoencodingEngine
[2024-06-18 13:50] Loading 1 new model
[2024-06-18 13:50] Loading weights to:  cpu
[2024-06-18 13:50] Diffusion using fp16
[2024-06-18 13:50] captions:  [['']]
[2024-06-18 13:50] Batch captioning
[2024-06-18 13:50] !!! Exception during processing!!! 'NoneType' object is not callable
[2024-06-18 13:50] Traceback (most recent call last):
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 151, in recursive_execute
    output_data, output_ui = get_output_data(obj, input_data_all)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 81, in get_output_data
    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\execution.py", line 74, in map_node_over_list
    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR\nodes_v2.py", line 617, in condition
    _c, _uc = SUPIR_model.conditioner.get_unconditional_conditioning(cond, uncond)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR\sgm\modules\encoders\modules.py", line 187, in get_unconditional_conditioning
    c = self(batch_c)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR\sgm\modules\encoders\modules.py", line 208, in forward
    emb_out = embedder(batch[embedder.input_key])
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Python310\lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Lightmapper\Documents\GitHub\ComfyUI\custom_nodes\ComfyUI-SUPIR\sgm\modules\encoders\modules.py", line 490, in forward
    batch_encoding = self.tokenizer(
TypeError: 'NoneType' object is not callable

[2024-06-18 13:50] Prompt executed in 16.65 seconds
[2024-06-18 13:57] 
Stopped server
